<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Haakon Bakka" />


<title>Analysing the Seeds data in INLA with a GAM/GLMM</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">My Website</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="organisedtopics.html">Organised Topics</a>
</li>
<li>
  <a href="alltopics.html">All Topics</a>
</li>
<li>
  <a href="aboutme.html">About me</a>
</li>
<li>
  <a href="feedback.html">Feedback</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Analysing the Seeds data in INLA with a GAM/GLMM</h1>
<h4 class="author">Haakon Bakka</h4>
<h4 class="date">BTopic102 updated 10 Sept 2018</h4>

</div>


<div id="about" class="section level2">
<h2>About</h2>
<p>This is a detailed example of a good model for a simple dataset called <strong>Seeds</strong>. The goal is to show an example of INLA with a simple model, using both fixed effects and random effects. For an overview of the words and concepts see <a href="words.html">the word-list</a>. (The name BTopic102 is a unique identifier for the weppage.)</p>
</div>
<div id="initialise-r-session" class="section level2">
<h2>0. Initialise R session</h2>
<p>We load any packages and set global options. You may need to install these libraries (<a href="btopic109.html">Installation and general troubleshooting</a>).</p>
<pre class="r"><code>library(INLA)</code></pre>
</div>
<div id="load-data-rename-rescale" class="section level2">
<h2>1. Load data, rename, rescale</h2>
<pre class="r"><code>data(Seeds)</code></pre>
<p>This <code>Seeds</code> is the original dataframe. We will keep <code>Seeds</code> unchanged, and create another object (<code>df</code>, our modeling dataframe) later. Next we explain the data.</p>
<pre class="r"><code># Run: ?Seeds
head(Seeds)</code></pre>
<pre><code>##    r  n x1 x2 plate
## 1 10 39  0  0     1
## 2 23 62  0  0     2
## 3 23 81  0  0     3
## 4 26 51  0  0     4
## 5 17 39  0  0     5
## 6  5  6  0  1     6</code></pre>
<pre class="r"><code># - r is the number of seed germinated (successes)
# - n is the number of seeds attempted (trials)
# - x1 is the type of seed
# - x2 is the type of root extract
# - plate is the numbering of the plates/experiments</code></pre>
<p>All the covariates are 0/1 factors, and the numbering of the plates are arbitrary. We do not re-scale any covariates. The observations are integers, so we do not re-scale these either.</p>
<pre class="r"><code>df = data.frame(y = Seeds$r, Ntrials = Seeds$n, Seeds[, 3:5])</code></pre>
<p>I always name the dataframe that is going to be used in the inference to <code>df</code>, keeping the original dataframe. The observations are always named <span class="math inline">\(y\)</span>.</p>
</div>
<div id="explore-data" class="section level2">
<h2>2. Explore data</h2>
<pre class="r"><code>summary(df)</code></pre>
<pre><code>##        y         Ntrials         x1             x2           plate   
##  Min.   : 0   Min.   : 4   Min.   :0.00   Min.   :0.00   Min.   : 1  
##  1st Qu.: 8   1st Qu.:16   1st Qu.:0.00   1st Qu.:0.00   1st Qu.: 6  
##  Median :17   Median :39   Median :0.00   Median :1.00   Median :11  
##  Mean   :20   Mean   :40   Mean   :0.48   Mean   :0.52   Mean   :11  
##  3rd Qu.:26   3rd Qu.:51   3rd Qu.:1.00   3rd Qu.:1.00   3rd Qu.:16  
##  Max.   :55   Max.   :81   Max.   :1.00   Max.   :1.00   Max.   :21</code></pre>
<pre class="r"><code>table(df$x1)</code></pre>
<pre><code>## 
##  0  1 
## 11 10</code></pre>
<pre class="r"><code>table(df$x2)</code></pre>
<pre><code>## 
##  0  1 
## 10 11</code></pre>
<p>This shows that no other covariates or factors are out of scale, or senseless. We note that there are several observations of each factor level.</p>
<p>Next we look at counfounding and outliers.</p>
<pre class="r"><code>plot(df)</code></pre>
<p><img src="btopic102_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>We see no problematic structure, or outliers. The relationship between <code>x1</code> and <code>plate</code> is not a problem (since <code>plate</code> values will be treated as an arbitrary enumeration in our model).</p>
</div>
<div id="observation-likelihood" class="section level2">
<h2>3. Observation Likelihood</h2>
<pre class="r"><code>family1 = &quot;binomial&quot;
control.family1 = list(control.link=list(model=&quot;logit&quot;))
# number of trials is df$Ntrials</code></pre>
<p>This specifies which likelihood we are going to use for the observations. The binomial distribution is defined with a certain number of trials, in INLA known as <code>Ntrials</code>. If there were hyper-parameters in our likelihood, we would specify the priors on these in <code>control.family</code>.</p>
<div id="mathematical-description" class="section level3">
<h3>Mathematical description</h3>
<p>The precise mathematical description of our likelihood is, <span class="math display">\[y_i \sim \text{Binom}(N_i, p_i) \]</span> with <span class="math display">\[\eta_i = \text{logit}(p_i). \]</span> We call <span class="math inline">\(\eta_i\)</span> (“eta i”) the predictor (or: linear predictor, latent variable, hidden state, …). This <span class="math inline">\(\eta_i\)</span> is a parameter where we believe a linear model to be somewhat sensible. (A linear model is completely senseless on <span class="math inline">\(p_i\)</span>.)</p>
</div>
</div>
<div id="formula" class="section level2">
<h2>4. Formula</h2>
<pre class="r"><code>hyper1 = list(theta = list(prior=&quot;pc.prec&quot;, param=c(1,0.01)))
formula1 = y ~ x1 + x2 + f(plate, model=&quot;iid&quot;, hyper=hyper1)</code></pre>
<p>This specifies the formula, and the priors for any hyper-parameters in the random effects. See <code>inla.doc(&quot;pc.prec&quot;)</code> for more details on this prior.</p>
<div id="mathematical-description-1" class="section level3">
<h3>Mathematical description</h3>
<p>The precise mathematical description of the model for our predictor <span class="math inline">\(\eta_i\)</span> is <span class="math display">\[\eta_i = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + v_i, \]</span> where <span class="math display">\[\beta_i \sim \mathcal N(0, 1000), \]</span> <span class="math display">\[v_i \sim \mathcal N(0, \sigma_v^2). \]</span></p>
<p>This is not yet a Bayesian model, since we have not defined the prior distribution (“simulating distribution”) for all parameters. We assume an exponential prior on <span class="math inline">\(v_i\)</span>, i.e. <span class="math display">\[\pi(\sigma_v) = \lambda e^{-\lambda \sigma_v}. \]</span> This is not yet a Bayesian model, as we have not defined a prior for <span class="math inline">\(\lambda\)</span>. We fix <span class="math inline">\(\lambda\)</span> so that <span class="math display">\[\pi(\sigma_v &gt; 1) = 0.01, \]</span> which means that <span class="math inline">\(\lambda = \frac{-log(0.01)}{1} \approx 4.6\)</span>.</p>
<p>Now we have a fully specified Bayesian model. After this, everything else is “just computations”, and then interpreting the results.</p>
</div>
</div>
<div id="call-inla" class="section level2">
<h2>5. Call INLA</h2>
<p>Next we run the inla-call, where we collect the variables we have defined.</p>
<pre class="r"><code>res1 = inla(formula=formula1, data=df, 
            family=family1, Ntrials=Ntrials, 
            control.family=control.family1)</code></pre>
<p>The <code>Ntrials</code> picks up the correct column in the dataframe.</p>
</div>
<div id="look-at-results" class="section level2">
<h2>6. Look at results</h2>
<pre class="r"><code>summary(res1)</code></pre>
<pre><code>## 
## Call:
##    c(&quot;inla(formula = formula1, family = family1, data = df, 
##    Ntrials = Ntrials, &quot;, &quot; control.family = control.family1)&quot;) 
## Time used:
##     Pre = 1.44, Running = 0.177, Post = 0.0735, Total = 1.69 
## Fixed effects:
##              mean   sd 0.025quant 0.5quant 0.97quant  mode kld
## (Intercept) -0.39 0.18      -0.73    -0.39    -0.044 -0.40   0
## x1          -0.35 0.23      -0.82    -0.35     0.055 -0.33   0
## x2           1.03 0.22       0.60     1.03     1.442  1.04   0
## 
## Random effects:
##   Name     Model
##     plate IID model
## 
## Model hyperparameters:
##                       mean      sd 0.025quant 0.5quant 0.97quant mode
## Precision for plate 111.06 1231.28       2.98    10.91    225.97 6.06
## 
## Expected number of effective parameters(stdev): 9.91(2.94)
## Number of equivalent replicates : 2.12 
## 
## Marginal log-Likelihood:  -68.44</code></pre>
<p>This summary shows many elements of the results, notably not including the random effects (the parameters are not shown). The total result, however, is a complex high-dimensional posterior.</p>
<pre class="r"><code># Run: str(res1, 1)</code></pre>
<p>This command, if run, shows one step in the list-of-lists hierarchy that is the inla result.</p>
</div>
<div id="look-at-the-random-effect" class="section level2">
<h2>7. Look at the random effect</h2>
<pre class="r"><code>res1$summary.random$plate</code></pre>
<pre><code>##    ID   mean   sd 0.025quant 0.5quant 0.97quant    mode     kld
## 1   1 -0.287 0.27     -0.896   -0.258     0.152 -0.1864 1.1e-04
## 2   2 -0.080 0.23     -0.559   -0.068     0.333 -0.0299 4.8e-05
## 3   3 -0.316 0.24     -0.844   -0.296     0.082 -0.2570 2.2e-04
## 4   4  0.217 0.24     -0.214    0.198     0.708  0.1452 1.0e-04
## 5   5  0.055 0.24     -0.421    0.049     0.526  0.0227 6.1e-05
## 6   6  0.098 0.31     -0.490    0.074     0.750  0.0198 4.0e-05
## 7   7  0.157 0.23     -0.264    0.142     0.618  0.0846 5.9e-05
## 8   8  0.284 0.24     -0.136    0.264     0.788  0.2192 1.6e-04
## 9   9 -0.061 0.23     -0.547   -0.052     0.372 -0.0232 6.0e-05
## 10 10 -0.187 0.22     -0.667   -0.171     0.203 -0.1210 9.5e-05
## 11 11  0.115 0.29     -0.428    0.090     0.721  0.0290 4.6e-05
## 12 12  0.206 0.30     -0.312    0.172     0.845  0.0614 7.1e-05
## 13 13  0.021 0.26     -0.494    0.016     0.529  0.0043 5.5e-05
## 14 14 -0.059 0.26     -0.608   -0.049     0.432 -0.0196 5.2e-05
## 15 15  0.387 0.29     -0.086    0.360     0.991  0.3051 2.9e-04
## 16 16 -0.126 0.33     -0.861   -0.094     0.443 -0.0261 3.1e-05
## 17 17 -0.291 0.32     -1.028   -0.248     0.215 -0.1026 6.9e-05
## 18 18 -0.060 0.24     -0.556   -0.054     0.402 -0.0270 6.0e-05
## 19 19 -0.110 0.25     -0.648   -0.096     0.358 -0.0421 6.6e-05
## 20 20  0.125 0.24     -0.325    0.105     0.627  0.0433 4.6e-05
## 21 21 -0.085 0.30     -0.739   -0.066     0.470 -0.0197 5.4e-05</code></pre>
</div>
<div id="plot-the-random-effect-quantiles" class="section level2">
<h2>8. Plot the random effect quantiles</h2>
<pre class="r"><code>plot(1:nrow(df), res1$summary.random$plate$`0.97`, col=&quot;red&quot;, ylim=c(-1,1),
     xlab=&quot;measurement number&quot;, ylab = &quot;quantiles&quot;)
points(1:nrow(df), res1$summary.random$plate$`0.5quant`)
points(1:nrow(df), res1$summary.random$plate$`0.02`, col=&quot;blue&quot;)</code></pre>
<p><img src="btopic102_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>The reason we use points instead of lines is that the numbering of the plates / experiments is arbitrary. Lines would falsely imply that one observation came “before/after” another (in time or on some other covariate).</p>
</div>
<div id="plot-the-marginal-of-a-fixed-effect" class="section level2">
<h2>9. Plot the marginal of a fixed effect</h2>
<pre class="r"><code>m.beta1 = inla.tmarginal(fun = function(x) x, marginal = 
                           res1$marginals.fixed$x1)
# - this transformation is the identity (does nothing)
# - m.beta1 is the marginal for the coefficient in front of the x1 covariate
plot(m.beta1, type=&quot;l&quot;, xlab = expression(beta[1]), ylab = &quot;Probability density&quot;)</code></pre>
<p><img src="btopic102_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
<div id="plot-the-marginal-of-a-hyper-parameter" class="section level2">
<h2>10. Plot the marginal of a hyper-parameter</h2>
<p>We must transform the marginal (<code>res1$marginals.hyperpar$&quot;Precision for plate&quot;</code>) to a parametrisation that makes sense to use for interpretation. The only parametrisation I like is <span class="math inline">\(\sigma\)</span>, marginal standard deviation. For numerical reasons, we need to transform the internal marginals. To find define the function used in the transformation, we look up the internal parametrisation, which is <span class="math inline">\(\log(precision)\)</span>, see <code>inla.doc(&quot;iid&quot;)</code>.</p>
<pre class="r"><code>m.sigma = inla.tmarginal(fun = function(x) exp(-1/2*x), marginal = 
                           res1$internal.marginals.hyperpar$`Log precision for plate`)
# - m.sigma is the marginal for the standard deviation parameter in the iid random effect
plot(m.sigma, type=&quot;l&quot;, xlab = expression(sigma[iid]), ylab = &quot;Probability density&quot;)</code></pre>
<p><img src="btopic102_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
</div>
<div id="plot-the-marginal-of-a-parameter" class="section level2">
<h2>11. Plot the marginal of a parameter</h2>
<pre class="r"><code>m.plate.7 = inla.tmarginal(fun = function(x) x, marginal = 
                           res1$marginals.random$plate$index.7)

# - m.plate.7 is one of the marginals for the parameters beloning to the plate iid effect
# - it is number 7, which corresponds to plate=7, which is our 7th row of data
plot(m.plate.7, type=&quot;l&quot;, xlab = &quot;marginal plate nr 7&quot;, ylab = &quot;Probability density&quot;)</code></pre>
<p><img src="btopic102_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
</div>
<div id="plot-the-distribution-of-random-effect-estimates" class="section level2">
<h2>12. Plot the distribution of random effect estimates</h2>
<p>Here we take the point estimates of the iid effect (posterior marginal medians).</p>
<pre class="r"><code>plot(density(res1$summary.random$plate$mean))
lines(0+c(-2, 2)*res1$summary.hyperpar$`0.5quant`^(-0.5) , c(0,0), col=&quot;blue&quot;)</code></pre>
<p><img src="btopic102_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<pre class="r"><code># - draw a blue line for plus/minus 2 sigma</code></pre>
<p>From this plot we see that the estimates of the random effect give a nice distribution, ending up within two standard deviations from zero. The assumption that the random effect is iid Gaussian looks reasonable.</p>
</div>
<div id="predictions" class="section level2">
<h2>Predictions</h2>
<p>What if we want to predict? On the same plate? On a new plate? With new covariate values? Here we provide one example.</p>
<pre class="r"><code>df2 = rbind(df, c(NA, 1, 0, 0, 22))
tail(df2)</code></pre>
<pre><code>##     y Ntrials x1 x2 plate
## 17  3      12  1  1    17
## 18 22      41  1  1    18
## 19 15      30  1  1    19
## 20 32      51  1  1    20
## 21  3       7  1  1    21
## 22 NA       1  0  0    22</code></pre>
<pre class="r"><code>res.pred = inla(formula=formula1, data=df2, 
            family=family1, Ntrials=Ntrials, 
            control.predictor = list(compute=T, link = 1),
            # - to get the posterior of the predictor and fitted values
            control.family=control.family1)</code></pre>
<pre class="r"><code>res.pred$summary.fitted.values[22, ]</code></pre>
<pre><code>##                     mean    sd 0.025quant 0.5quant 0.97quant mode
## fitted.Predictor.22 0.41 0.088       0.24      0.4      0.59  0.4</code></pre>
<pre class="r"><code># - this is the inv.logit(eta_i), namely p_i</code></pre>
</div>
<div id="comparing-two-models" class="section level2">
<h2>Comparing two models</h2>
<p>An alternative to using the logit link would be to use the probit link. Changing the likelihood in this way also changes the behaviour of the linear predictor.</p>
<pre class="r"><code>control.family2 = list(control.link=list(model=&quot;probit&quot;))
res1 = inla(formula=formula1, data=df, 
            family=family1, Ntrials=Ntrials, 
            control.predictor = list(compute=T, link=1),
            # - to get the posterior of the predictor and fitted values
            control.family=control.family1)
res2 = inla(formula=formula1, data=df, 
            family=family1, Ntrials=Ntrials, 
            control.predictor = list(compute=T, link=1),
            # - to get the posterior of the predictor and fitted values
            control.family=control.family2)</code></pre>
<pre class="r"><code>a = data.frame(y=df$y, ps=df$y/df$Ntrials,
               r1eta = res1$summary.linear.predictor$mean,
           r2eta = res2$summary.linear.predictor$mean,
           r1fit = res1$summary.fitted.values$mean,
           r2fit = res2$summary.fitted.values$mean)
round(a, 2)</code></pre>
<pre><code>##     y   ps r1eta r2eta r1fit r2fit
## 1  10 0.26 -0.67 -0.43  0.34  0.33
## 2  23 0.37 -0.47 -0.29  0.39  0.39
## 3  23 0.28 -0.70 -0.45  0.33  0.33
## 4  26 0.51 -0.17 -0.09  0.46  0.46
## 5  17 0.44 -0.33 -0.20  0.42  0.42
## 6   5 0.83  0.74  0.47  0.67  0.68
## 7  53 0.72  0.80  0.50  0.69  0.69
## 8  55 0.76  0.92  0.59  0.71  0.72
## 9  32 0.63  0.58  0.36  0.64  0.64
## 10 46 0.58  0.46  0.28  0.61  0.61
## 11 10 0.77  0.76  0.48  0.68  0.68
## 12  8 0.50 -0.53 -0.32  0.37  0.38
## 13 10 0.33 -0.72 -0.45  0.33  0.33
## 14  8 0.29 -0.80 -0.50  0.31  0.31
## 15 23 0.51 -0.35 -0.20  0.41  0.42
## 16  0 0.00 -0.87 -0.55  0.30  0.30
## 17  3 0.25  0.00 -0.03  0.50  0.49
## 18 22 0.54  0.23  0.14  0.56  0.55
## 19 15 0.50  0.18  0.10  0.54  0.54
## 20 32 0.63  0.41  0.26  0.60  0.60
## 21  3 0.43  0.20  0.12  0.55  0.55</code></pre>
</div>
<div id="comments" class="section level2">
<h2>Comments</h2>
<div id="see-also" class="section level3">
<h3>See also</h3>
<p>Read the review paper <span class="citation">(see Rue et al. 2016)</span>, and see the references therein! Also, explore www.r-inla.org, both the resources and the discussion group. And, use the function <code>inla.doc</code> in <code>R</code> to find information related to a keyword (e.g. a likelihood).</p>
</div>
<div id="more-details-on-df-in-general" class="section level3">
<h3>More details on <code>df</code> in general</h3>
<p>This dataframe contains only numerical values, and all factors have been expanded. All covariates have a mean near zero and a standard deviation near 1 (i.e. 0.1&lt;sd&lt;10). They are also transformed to the appropriate scale, often with a <code>log</code>.</p>
</div>
<div id="mean-median-or-mode" class="section level3">
<h3>Mean, median or mode?</h3>
<p>What point estimate should you use? Mean, median or mode?</p>
<p>The mode, is usually the wrong answer. This is where the posterior is maximised, which would be similar to a penalised maximum likelihood. But, it is generally understood that the median and mean are better, both as they have nicer statistical properties, a more “valid” loss function, and experience shows that they are more stable and less error prone.</p>
<p>Choosing between the median and mean is more difficult. In most cases, the difference is very small, especially for “good” parametrisations. I personally prefer the median (0.5 quantile), for several reasons</p>
<ol style="list-style-type: decimal">
<li><p>You can transform (between parametrisations) “directly” (eg using <code>^(-0.5)</code>as in the code),</p></li>
<li><p>Estimates are independent of the internal choice of parameters (in the computer code).</p></li>
<li><p>I prefer the interpretation of the absolute loss function to that of a quadratic loss function for hyper-parameters.</p></li>
</ol>
</div>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-rue2016bayesian">
<p>Rue, Håvard, Andrea Riebler, Sigrunn H Sørbye, Janine B Illian, Daniel P Simpson, and Finn K Lindgren. 2016. “Bayesian Computing with Inla: A Review.” <em>arXiv Preprint arXiv:1604.00860</em>.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
